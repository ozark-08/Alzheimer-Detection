# -*- coding: utf-8 -*-
"""U-NetApply.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L_gq2i2AZg-t76Da7GdkC-WspN0UWKJ1
"""

import tensorflow as tf
import os
import random
import numpy as np
from tqdm import tqdm
import cv2

from skimage.io import imread, imshow
from skimage.transform import resize
import matplotlib.pyplot as plt

"""seed generate same sequence of random numbers every time a code is run
helpful when random numbers that are repeatable and predictable are to be generated
"""

seed = 42 
#function in numpy library
np.random.seed = seed #this is done to keep the results in sync, otherwise random seed values are generated.

IMG_WIDTH = 128
IMG_HEIGHT = 128
IMG_CHANNELS = 3

from google.colab import drive

drive.mount('/content/drive')

train_path = '/content/drive/MyDrive/Colab Notebooks/training'
test_path = '/content/drive/MyDrive/Colab Notebooks/test'

train_path_AD = '/content/drive/MyDrive/Colab Notebooks/training/AD'
train_path_CN = '/content/drive/MyDrive/Colab Notebooks/training/CN'

train_path_ADflat = '/content/drive/MyDrive/Colab Notebooks/training/AD_FLAT'
train_path_CNflat = '/content/drive/MyDrive/Colab Notebooks/training/CN_FLAT'

train_path_ADflat

# next(os.walk(train_path_CNflat))[2] #dirpath,dirname,filename -> array elements

train_id = []
# train_id = train_id + next(os.walk(train_path_ADflat))[2]+ next(os.walk(train_path_CNflat))[2]
for k in next(os.walk(train_path_ADflat))[2]:
  pth = train_path_ADflat +'/'+ k
  # print(pth)
  # pth_id = next(os.walk(pth))[2]
  # print(pth_id)
  train_id.append(pth)
  # print(train_id)

for k in next(os.walk(train_path_CNflat))[2]:
  pth = train_path_CNflat +'/'+ k
  # print(pth)
#   # pth_id = next(os.walk(pth))[2]
#   # print(pth_id)
  train_id.append(pth)
  # print(train_id)

type(train_id)

X_train =  np.zeros((len(train_id), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(train_id), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)
# Y_train = np.zeros((len(train_id),1), dtype=bool)

Y_train.shape

type(Y_train)

print('resising training images')

# for n, id in enumerate(train_id):
#   pth = train_path +'/'+ id
#   # print(pth)
#   files = os.listdir(pth)
#   # print(files)
#   for j in files:
#     pth2 = pth + '/' + j
#     # print(pth2)
#     # img = os.listdir(pth2)
#     # print(img)
#     for k in os.listdir(pth2):
#       # print(pth2 + '/' + k )
#       img = cv2.imread(pth2 + '/' + k )
#       # print(img)
#       img = resize(img,(IMG_HEIGHT, IMG_WIDTH), mode = 'constant', preserve_range = True)
#       X_train[n] = img
#       # print(X_train)
#       Y_train[n] = classes[id]
#       # print(Y_train)

classes = {'AD':0, 'CN':1}
classes['AD']

for n, id in enumerate(train_id):
  
      img = cv2.imread(id )
      # print(img)
      img = resize(img,(IMG_HEIGHT, IMG_WIDTH), mode = 'constant', preserve_range = True)
      X_train[n] = img
      # print(X_train)
      if(id.find('AD') != -1):
        Y_train[n] = classes['AD']
      elif(id.find('CN') != -1):
        Y_train[n] = classes['CN']

  
      # Y_train[n] = classes[id]
      # print(Y_train)

# Y_train

Y_train.shape

# Y_train = Y_train.reshape(Y_train.shape[0],128,128,3)

# from tensorflow.keras.utils import to_categorical
# Y_train = to_categorical(Y_train, 128,3)

X_train.shape

type(X_train)

image_x = random.randint(0, len(train_id))
imshow(X_train[image_x])
plt.show()
# imshow(np.squeeze(Y_train[image_x]))
# plt.show()

#Build the model
inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)

#Contraction path
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
c1 = tf.keras.layers.Dropout(0.1)(c1)
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
c2 = tf.keras.layers.Dropout(0.1)(c2)
c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3)
c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)

c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4)
c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)

c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

#Expansive path 
u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1], axis=3)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)

outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)

model = tf.keras.Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

"""Callbacks are utilites called at certain point during model training
for say stopping the epochs a certain stage if improvements are not visible

"""

#Modelcheckpoint: chechks the result at every epoch and save the same in case of any discripancy later
checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_alzheimer.h5', verbose=1, save_best_only=True)

#EarlyStopping and TensorBoard are types of callbacks mentioned in tensorflow documentation
callbacks = [
        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),
        tf.keras.callbacks.TensorBoard(log_dir='logs')]

results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks)
# results = model.fit(X_train, Y_train, batch_size=16, epochs=25, callbacks=callbacks)

plt.figure(figsize=(5,5))
plt.plot(results.history['accuracy'],label='train acc')
plt.plot(results.history['val_accuracy'],label='val acc')
plt.legend
plt.title('train Accuracy')
plt.show

#visualisation
plt.figure(figsize=(5,5))
plt.plot(results.history['accuracy'],label='train acc')
# plt.plot(results.history['val_accuracy'],label='val acc')
plt.legend
plt.title('train Accuracy')
plt.show

plt.figure(figsize=(5,5))
plt.plot(results.history['loss'],label='train loss')
# plt.plot(results.history['val_loss'],label='val loss')
plt.legend
plt.title('Loss')
plt.show

plt.figure(figsize=(5,5))
plt.plot(results.history['loss'],label='train loss')
plt.plot(results.history['val_loss'],label='val loss')
plt.legend
plt.title('Loss')
plt.show

test_path_ADflat = '/content/drive/MyDrive/Colab Notebooks/test/test_AD_FLAT'
test_path_CNflat = '/content/drive/MyDrive/Colab Notebooks/test/test_CN_FLAT'

test_id = []
# train_id = train_id + next(os.walk(train_path_ADflat))[2]+ next(os.walk(train_path_CNflat))[2]
for k in next(os.walk(test_path_ADflat))[2]:
  pth = test_path_ADflat +'/'+ k
  # print(pth)
  # pth_id = next(os.walk(pth))[2]
  # print(pth_id)
  test_id.append(pth)
  # print(train_id)

for k in next(os.walk(test_path_CNflat))[2]:
  pth = test_path_CNflat +'/'+ k
  # print(pth)
#   # pth_id = next(os.walk(pth))[2]
#   # print(pth_id)
  test_id.append(pth)
  # print(train_id)

#testing data:
X_test =  np.zeros((len(test_id), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
Y_test = np.zeros((len(test_id), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)

for n, id in enumerate(test_id):
  
      img = cv2.imread(id )
      # print(img)
      img = resize(img,(IMG_HEIGHT, IMG_WIDTH), mode = 'constant', preserve_range = True)
      X_test[n] = img
      # print(X_train)
      if(id.find('AD') != -1):
        Y_test[n] = classes['AD']
      elif(id.find('CN') != -1):
        Y_test[n] = classes['CN']

X_test.shape

Y_test.shape

model.evaluate(X_test,Y_test,batch_size = 32)

